{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a server\n",
    "\n",
    "This code uses `subprocess.Popen` to start an SGLang server process, equivalent to executing \n",
    "\n",
    "```bash\n",
    "python -m sglang.launch_server --model-path meta-llama/Meta-Llama-3.1-8B-Instruct --port 30000 \\\n",
    "--api-key sk-None-hello-world --host 0.0.0.0 --log-level warning\n",
    "```\n",
    "in your command line and wait for the server to be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready. Proceeding with the next steps.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "server_process = subprocess.Popen(\n",
    "    [\n",
    "        \"python\",\n",
    "        \"-m\",\n",
    "        \"sglang.launch_server\",\n",
    "        \"--model-path\",\n",
    "        \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"--port\",\n",
    "        \"30000\",\n",
    "        \"--api-key\",\n",
    "        \"sk-None-hello-world\",\n",
    "        \"--host\",\n",
    "        \"0.0.0.0\",\n",
    "        \"--log-level\",\n",
    "        \"error\",\n",
    "    ],\n",
    "    text=True,\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"http://localhost:30000/v1/models\",\n",
    "            headers={\"Authorization\": \"Bearer sk-None-hello-world\"},\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "    except requests.exceptions.RequestException:\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"Server is ready. Proceeding with the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a Request\n",
    "\n",
    "Once the server is running, you can send test requests using curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"865df79b13d14105b824e580c12e4179\",\"object\":\"chat.completion\",\"created\":1729750400,\"model\":\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"LLM stands for Large Language Model. It's a type of artificial intelligence (AI) designed to process and generate human-like language. LLMs are trained on vast amounts of text data, allowing them to learn patterns, relationships, and context in language.\\n\\nLarge Language Models use complex algorithms and neural networks to analyze and understand the meaning of words, phrases, and sentences. They can then generate text, answer questions, translate languages, and even create original content like stories or conversations.\\n\\nSome key features of LLMs include:\\n\\n1. **Natural Language Understanding (NLU)**: LLMs can comprehend language nuances, idioms, and context, making them effective at understanding human language.\\n2. **Language Generation**: LLMs can generate text, responses, or even entire articles based on the input they receive.\\n3. **Syntax and Semantics**: LLMs can analyze and understand the structure and meaning of language, making them effective at tasks like question answering and text classification.\\n4. **Contextual Understanding**: LLMs can understand the context in which language is used, such as the topic, tone, and intent behind a message.\\n\\nLLMs have many applications, including:\\n\\n1. **Virtual Assistants**: LLMs power virtual assistants like Siri, Alexa, and Google Assistant.\\n2. **Chatbots**: LLMs enable chatbots to understand and respond to user queries.\\n3. **Language Translation**: LLMs can translate languages in real-time, making them a valuable tool for international communication.\\n4. **Content Creation**: LLMs can generate content, such as articles, social media posts, and even entire books.\\n\\nHowever, LLMs also have limitations and challenges, such as:\\n\\n1. **Bias and Accuracy**: LLMs can perpetuate biases and inaccuracies present in the training data.\\n2. **Limited Domain Knowledge**: LLMs may not have in-depth knowledge of specific domains or industries.\\n3. **Evaluation and Accountability**: LLMs can be difficult to evaluate and hold accountable, particularly in high-stakes applications.\\n\\nOverall, LLMs have the potential to revolutionize the way we interact with language and technology, but it's essential to be aware of their limitations and challenges.\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":128009}],\"usage\":{\"prompt_tokens\":47,\"total_tokens\":499,\"completion_tokens\":452,\"prompt_tokens_details\":null}}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:30000/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer sk-None-hello-world\" \\\n",
    "  -d '{\"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is a LLM?\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Compatible API\n",
    "\n",
    "SGLang supports OpenAI-compatible APIs. Here are Python examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='13b434c7cede4baabae4beb529ad2295', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are 3 countries and their capitals:\\n\\n1. **Country:** Japan\\n**Capital:** Tokyo\\n\\n2. **Country:** Australia\\n**Capital:** Canberra\\n\\n3. **Country:** Brazil\\n**Capital:** Bras√≠lia', refusal=None, role='assistant', function_call=None, tool_calls=None), matched_stop=128009)], created=1729750401, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=49, total_tokens=95, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Always assign an api_key, even if not specified during server initialization.\n",
    "# Setting an API key during server initialization is strongly recommended.\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://127.0.0.1:30000/v1\", api_key=\"sk-None-hello-world\"\n",
    ")\n",
    "\n",
    "# Chat completion example\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=64,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Embedding Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding server is ready. Proceeding with the next steps.\n"
     ]
    }
   ],
   "source": [
    "server_process.terminate()\n",
    "\n",
    "# Start a new server process for embedding models\n",
    "# Equivalent to running this in the shell:\n",
    "# python -m sglang.launch_server --model-path Alibaba-NLP/gte-Qwen2-7B-instruct --port 30010 --api-key sk-None-hello-world --host 0.0.0.0 --is-embedding --log-level error\n",
    "embedding_process = subprocess.Popen(\n",
    "    [\n",
    "        \"python\",\n",
    "        \"-m\",\n",
    "        \"sglang.launch_server\",\n",
    "        \"--model-path\",\n",
    "        \"Alibaba-NLP/gte-Qwen2-7B-instruct\",\n",
    "        \"--port\",\n",
    "        \"30010\",\n",
    "        \"--api-key\",\n",
    "        \"sk-None-hello-world\",\n",
    "        \"--host\",\n",
    "        \"0.0.0.0\",\n",
    "        \"--is-embedding\",\n",
    "        \"--log-level\",\n",
    "        \"error\",\n",
    "    ],\n",
    "    text=True,\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"http://localhost:30010/v1/models\",\n",
    "            headers={\"Authorization\": \"Bearer sk-None-hello-world\"},\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "    except requests.exceptions.RequestException:\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"Embedding server is ready. Proceeding with the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0083160400390625, 0.0006804466247558594, -0.00809478759765625, -0.0006995201110839844, 0.0143890380859375, -0.0090179443359375, 0.01238250732421875, 0.00209808349609375, 0.0062103271484375, -0.003047943115234375]\n"
     ]
    }
   ],
   "source": [
    "# Get the first 10 elements of the embedding\n",
    "\n",
    "! curl -s http://localhost:30010/v1/embeddings \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer sk-None-hello-world\" \\\n",
    "  -d '{\"model\": \"Alibaba-NLP/gte-Qwen2-7B-instruct\", \"input\": \"Once upon a time\"}' \\\n",
    "  | python3 -c \"import sys, json; print(json.load(sys.stdin)['data'][0]['embedding'][:10])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Compatible API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00603485107421875, -0.0190582275390625, -0.01273345947265625, 0.01552581787109375, 0.0066680908203125, -0.0135955810546875, 0.01131439208984375, 0.0013713836669921875, -0.0089874267578125, 0.021759033203125]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://127.0.0.1:30010/v1\", api_key=\"sk-None-hello-world\"\n",
    ")\n",
    "\n",
    "# Text embedding example\n",
    "response = client.embeddings.create(\n",
    "    model=\"Alibaba-NLP/gte-Qwen2-7B-instruct\",\n",
    "    input=\"How are you today\",\n",
    ")\n",
    "\n",
    "embedding = response.data[0].embedding[:10]\n",
    "print(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaMeemory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
