{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Engine API\n",
    "\n",
    "SGLang provides a direct inference engine without the need for an HTTP server, especially for use cases where additional HTTP server adds unnecessary complexity or overhead. Here are two general use cases:\n",
    "\n",
    "- Offline Batch Inference\n",
    "- Custom Server on Top of the Engine\n",
    "\n",
    "This document focuses on the offline batch inference, demonstrating four different inference modes:\n",
    "\n",
    "- Non-streaming synchronous generation\n",
    "- Streaming synchronous generation\n",
    "- Non-streaming asynchronous generation\n",
    "- Streaming asynchronous generation\n",
    "\n",
    "Additionally, you can easily build a custom server on top of the SGLang offline engine. A detailed example working in a python script can be found in [custom_server](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/custom_server.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Batch Inference\n",
    "\n",
    "SGLang offline engine supports batch inference with efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-16 02:40:00,058\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.04it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.62it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.37it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.26it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:05<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# launch the offline engine\n",
    "from sglang.utils import stream_and_merge, async_stream_and_merge\n",
    "import sglang as sgl\n",
    "import asyncio\n",
    "from sglang.test.test_utils import is_in_ci\n",
    "\n",
    "if is_in_ci():\n",
    "    import patch\n",
    "\n",
    "\n",
    "llm = sgl.Engine(model_path=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Caroline and I am a naturopathic nurse. I am excited to offer my services to patients in a holistic and compassionate environment. I aim to empower you with knowledge and tools to take charge of your health and well-being.\n",
      "What do I offer?\n",
      "I am passionate about promoting health and well-being through natural therapies and lifestyle modifications. I offer a range of services including:\n",
      "Nutrition and diet planning\n",
      "Hormone balancing and menopause support\n",
      "Stress management and relaxation techniques\n",
      "Sleep improvement and insomnia support\n",
      "Detoxification and cleansing\n",
      "Women's health and fertility support\n",
      "Bodywork and massage\n",
      "Energy healing and chakra balancing\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  a crucial position that requires a unique blend of leadership, diplomacy, and strategic thinking. The president serves as both the head of state and the head of government, overseeing the executive branch and working with Congress to pass legislation.\n",
      "Key Responsibilities of the President\n",
      "The president has a wide range of responsibilities, including:\n",
      "Conducting foreign policy and negotiating treaties\n",
      "Appointing federal judges, ambassadors, and other high-ranking officials\n",
      "Signing or vetoing legislation passed by Congress\n",
      "Commanding the armed forces\n",
      "Serving as commander-in-chief of the military\n",
      "Representing the United States at international events and summits\n",
      "Signing executive orders and regulations\n",
      "Leading\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text:  Paris. It is situated in the north-central part of the country, where the River Seine flows into the English Channel. Paris is a city of great historical and cultural significance, known for its stunning architecture, art museums, and romantic atmosphere. The city has a long history dating back to the Roman era, and has been influenced by various cultures, including the Gauls, the Franks, and the French monarchy. Today, Paris is a major tourist destination, attracting millions of visitors each year. It is home to the famous Eiffel Tower, Notre Dame Cathedral, the Louvre Museum, and many other iconic landmarks.\n",
      "The E\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  bright, but it will also bring challenges and changes to the workplace\n",
      "by Admin · Published August 2, 2020 · Updated September 18, 2020\n",
      "Artificial intelligence (AI) is rapidly changing the world we live in. It has the potential to improve efficiency, productivity, and decision-making in various industries, but it also raises concerns about job displacement, bias, and accountability. The impact of AI on the future of work will be significant, and it is essential to understand the opportunities and challenges it presents.\n",
      "AI will automate many routine and repetitive tasks, freeing up human workers to focus on higher-value tasks that require\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation with overlap removal ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  Elianore Quasar. I'm a 25-year-old astrophysicist with a passion for studying black holes. I'm currently working on a research project to better understand the properties of event horizons. When I'm not in the lab, you can find me hiking in the mountains or reading about the latest discoveries in the field of cosmology. I'm looking forward to meeting new people and learning from their experiences.\n",
      "This self-introduction is neutral because it doesn't reveal any personal opinions or biases. It simply states the character's name, profession, and interests in a straightforward and factual way. This is a good way\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "The capital of France is Paris. The city is located in the northern part of the country and is situated on the Seine River. Paris is known for its rich history, cultural landmarks, and romantic atmosphere. The city is home to many famous museums, including the Louvre, which houses the Mona Lisa, and the Orsay Museum, which features an impressive collection of Impressionist art. Paris is also famous for its fashion, cuisine, and architecture, including the iconic Eiffel Tower. The city has a population of over 2.1 million people and is a major hub for international business, finance, and tourism\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  likely to be shaped by several factors, including advancements in machine learning, natural language processing, and computer vision. Here are some possible future trends in AI:\n",
      "1. Increased use of AI in healthcare: AI is likely to play a larger role in healthcare, including diagnosis, treatment, and patient care. AI-powered systems may be able to analyze medical images, identify patterns in patient data, and provide personalized treatment recommendations.\n",
      "2. Widespread adoption of AI in customer service: AI-powered chatbots and virtual assistants are likely to become more common in customer service, helping to answer customer inquiries, resolve issues, and provide personalized support.\n",
      "3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation with overlap removal ===\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    merged_output = stream_and_merge(llm, prompt, sampling_params)\n",
    "    print(\"Generated text:\", merged_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous batch generation ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  Elliot, and I'm a 32-year-old resident of Seattle. I enjoy hiking and spending time outdoors. I'm currently working as a software engineer at a local tech company. That's a little about me.\n",
      "How would you like to change this introduction? Maybe make it more interesting?\n",
      "You could start by adding more details about Elliot's personality or interests. For example, you could mention that he's a bit of a perfectionist, or that he's passionate about environmental issues.\n",
      "Another option would be to add more details about Elliot's background or life story. For example, you could mention that he grew up in a small town in\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "Provide a concise factual statement about France’s population. France has a population of approximately 67.2 million people.\n",
      "Provide a concise factual statement about France’s geographical location. France is located in Western Europe, bordered by Belgium, Luxembourg, Germany, Switzerland, Italy, Spain, and Andorra.\n",
      "Provide a concise factual statement about France’s official language. The official language of France is French.\n",
      "Provide a concise factual statement about France’s highest point. The highest point in France is Mont Blanc, at an elevation of 4,810 meters (15,781 feet).  ## Additional Information\n",
      "France has a diverse and rich cultural heritage\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  going to be bright. The current pace of AI innovation is incredibly rapid, with new breakthroughs and advancements being made all the time. As AI technology continues to advance, we can expect to see many exciting and potentially transformative changes in the years to come. Here are some possible future trends in artificial intelligence:\n",
      "1. AI systems becoming increasingly autonomous:\n",
      "As AI technology advances, we can expect to see AI systems becoming increasingly autonomous. This means that AI systems will be able to make decisions and take actions without human intervention, which will be a significant shift in how we interact with AI.\n",
      "2. Increased use of natural language processing (NLP):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous batch generation ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    outputs = await llm.async_generate(prompts, sampling_params)\n",
    "\n",
    "    for prompt, output in zip(prompts, outputs):\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated text: {output['text']}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous streaming generation (no repeats) ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  Elianore Quasar. I'm a 25-year-old scientist with a background in astrobiology and planetary geology. I've spent the past five years researching the conditions necessary for life to exist beyond Earth. Currently, I'm part of a research team studying the potential for life on Mars. That's me in a nutshell. What do you think? Is it good? Should I add or change anything?\n",
      "Write a brief, descriptive scene that sets the context for the story. The Mars research facility was a self-contained city, built into the rocky walls of a valley on the Martian equator. The air was thin and cold,\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "Paris, the capital of France, has a rich history and is known for its iconic landmarks such as the Eiffel Tower, Notre Dame Cathedral, and the Louvre Museum. Paris is also a center for art, fashion, and cuisine. The city is divided into 20 arrondissements (districts) and is home to many famous parks and gardens, including the Luxembourg Gardens and the Tuileries Garden. Paris is a popular tourist destination and is considered one of the most romantic cities in the world.\n",
      "The city is a global center for business and finance, and is home to the headquarters of the European Space Agency\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  shrouded in uncertainty, but several trends are likely to shape the field in the coming years. Here are some possible future trends in artificial intelligence:\n",
      "1. Increased Adoption in Industry and Consumer Spaces:\n",
      "Artificial intelligence (AI) is already transforming various industries, such as healthcare, finance, and transportation. Its adoption is expected to continue, with more businesses and consumers using AI-powered solutions to improve efficiency, productivity, and decision-making.\n",
      "2. Advancements in Edge AI:\n",
      "As the number of connected devices increases, edge AI is likely to become more prevalent. This involves processing data closer to the source, reducing latency and improving real-time decision\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous streaming generation (no repeats) ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(\"Generated text: \", end=\"\", flush=True)\n",
    "\n",
    "        # Replace direct calls to async_generate with our custom overlap-aware version\n",
    "        async for cleaned_chunk in async_stream_and_merge(llm, prompt, sampling_params):\n",
    "            print(cleaned_chunk, end=\"\", flush=True)\n",
    "\n",
    "        print()  # New line after each prompt\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/multiprocessing/resource_tracker.py:123: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.02it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.59it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.40it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.27it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.30it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "llm = sgl.Engine(\n",
    "    model_path=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", return_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Ali and I'm a freelance writer. I've\n",
      "Prompt_Tokens: 6\tCompletion_tokens: 10\n",
      "Hidden states: [torch.Size([6, 4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096])]\n",
      "\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  the head of state and head of government of the\n",
      "Prompt_Tokens: 8\tCompletion_tokens: 10\n",
      "Hidden states: [torch.Size([8, 4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096])]\n",
      "\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text:  getting a facelift! Paris is changing its\n",
      "Prompt_Tokens: 6\tCompletion_tokens: 10\n",
      "Hidden states: [torch.Size([6, 4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096])]\n",
      "\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  being shaped by the need for more transparency and explain\n",
      "Prompt_Tokens: 6\tCompletion_tokens: 10\n",
      "Hidden states: [torch.Size([6, 4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096]), torch.Size([4096])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95, \"max_new_tokens\": 10}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params=sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(\n",
    "        f\"Prompt: {prompt}\\nGenerated text: {output['text']}\\nPrompt_Tokens: {output['meta_info']['prompt_tokens']}\\tCompletion_tokens: {output['meta_info']['completion_tokens']}\\nHidden states: {[i.shape for i in output['meta_info']['hidden_states']]}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
