nohup: ignoring input
Namespace(backend='sglang', base_url=None, host='0.0.0.0', port=40000, dataset_name='random', dataset_path='', model='deepseek-ai/DeepSeek-V3', tokenizer=None, num_prompts=300, sharegpt_output_len=None, random_input_len=1024, random_output_len=1024, random_range_ratio=1.0, request_rate=1.0, max_concurrency=None, seed=1, multi=False, request_rate_range='2,34,2', output_file='deepseek_v3_2x8h200_FP8_online_output.jsonl', disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, return_logprob=False, extra_request_body=None, gen_num_groups=64, gen_prompts_per_group=16, gen_system_prompt_len=2048, gen_question_len=128, gen_output_len=256, profile=False, lora_name=None)

#Input tokens: 307200
#Output tokens: 307200
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run... 

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    1.0       
Max reqeuest concurrency:                not set   
Successful requests:                     300       
Benchmark duration (s):                  1131.09   
Total input tokens:                      307200    
Total generated tokens:                  307200    
Total generated tokens (retokenized):    306092    
Request throughput (req/s):              0.27      
Input token throughput (tok/s):          271.60    
Output token throughput (tok/s):         271.60    
Total token throughput (tok/s):          543.19    
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   982681.06 
Median E2E Latency (ms):                 985610.62 
---------------Time to First Token----------------
Mean TTFT (ms):                          99781.93  
Median TTFT (ms):                        56824.07  
P99 TTFT (ms):                           244007.03 
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          863.05    
Median TPOT (ms):                        862.84    
P99 TPOT (ms):                           1084.94   
---------------Inter-token Latency----------------
Mean ITL (ms):                           863.05    
Median ITL (ms):                         662.33    
P99 ITL (ms):                            695.39    
==================================================
Namespace(backend='sglang', base_url=None, host='0.0.0.0', port=40000, dataset_name='random', dataset_path='', model='deepseek-ai/DeepSeek-V3', tokenizer=None, num_prompts=600, sharegpt_output_len=None, random_input_len=1024, random_output_len=1024, random_range_ratio=1.0, request_rate=2.0, max_concurrency=None, seed=1, multi=False, request_rate_range='2,34,2', output_file='deepseek_v3_2x8xh200_FP8_online_output.jsonl', disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, return_logprob=False, extra_request_body=None, gen_num_groups=64, gen_prompts_per_group=16, gen_system_prompt_len=2048, gen_question_len=128, gen_output_len=256, profile=False, lora_name=None)

#Input tokens: 614400
#Output tokens: 614400
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    2.0       
Max reqeuest concurrency:                not set   
Successful requests:                     600       
Benchmark duration (s):                  2130.27   
Total input tokens:                      614400    
Total generated tokens:                  614400    
Total generated tokens (retokenized):    612142    
Request throughput (req/s):              0.28      
Input token throughput (tok/s):          288.41    
Output token throughput (tok/s):         288.41    
Total token throughput (tok/s):          576.83    
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   1978002.69
Median E2E Latency (ms):                 1975371.99
---------------Time to First Token----------------
Mean TTFT (ms):                          309169.92 
Median TTFT (ms):                        305318.37 
P99 TTFT (ms):                           609895.40 
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          1631.31   
Median TPOT (ms):                        1632.35   
P99 TPOT (ms):                           2057.38   
---------------Inter-token Latency----------------
Mean ITL (ms):                           1631.34   
Median ITL (ms):                         1219.14   
P99 ITL (ms):                            1537.46   
==================================================
Namespace(backend='sglang', base_url=None, host='0.0.0.0', port=40000, dataset_name='random', dataset_path='', model='deepseek-ai/DeepSeek-V3', tokenizer=None, num_prompts=1200, sharegpt_output_len=None, random_input_len=1024, random_output_len=1024, random_range_ratio=1.0, request_rate=4.0, max_concurrency=None, seed=1, multi=False, request_rate_range='2,34,2', output_file='deepseek_v3_2x8xh200_FP8_online_output.jsonl', disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, return_logprob=False, extra_request_body=None, gen_num_groups=64, gen_prompts_per_group=16, gen_system_prompt_len=2048, gen_question_len=128, gen_output_len=256, profile=False, lora_name=None)

#Input tokens: 1228800
#Output tokens: 1228800
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    4.0       
Max reqeuest concurrency:                not set   
Successful requests:                     1200      
Benchmark duration (s):                  4564.80   
Total input tokens:                      1228800   
Total generated tokens:                  1228800   
Total generated tokens (retokenized):    1224515   
Request throughput (req/s):              0.26      
Input token throughput (tok/s):          269.19    
Output token throughput (tok/s):         269.19    
Total token throughput (tok/s):          538.38    
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   3929702.07
Median E2E Latency (ms):                 3901390.30
---------------Time to First Token----------------
Mean TTFT (ms):                          767128.52 
Median TTFT (ms):                        767082.14 
P99 TTFT (ms):                           1504428.26
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          3091.47   
Median TPOT (ms):                        3023.99   
P99 TPOT (ms):                           3886.39   
---------------Inter-token Latency----------------
Mean ITL (ms):                           3091.12   
Median ITL (ms):                         2189.83   
P99 ITL (ms):                            2596.82   
==================================================
Namespace(backend='sglang', base_url=None, host='0.0.0.0', port=40000, dataset_name='random', dataset_path='', model='deepseek-ai/DeepSeek-V3', tokenizer=None, num_prompts=2400, sharegpt_output_len=None, random_input_len=1024, random_output_len=1024, random_range_ratio=1.0, request_rate=8.0, max_concurrency=None, seed=1, multi=False, request_rate_range='2,34,2', output_file='deepseek_v3_2x8xh200_FP8_online_output.jsonl', disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, return_logprob=False, extra_request_body=None, gen_num_groups=64, gen_prompts_per_group=16, gen_system_prompt_len=2048, gen_question_len=128, gen_output_len=256, profile=False, lora_name=None)

#Input tokens: 2457600
#Output tokens: 2457600
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    8.0       
Max reqeuest concurrency:                not set   
Successful requests:                     2400      
Benchmark duration (s):                  8880.48   
Total input tokens:                      2457600   
Total generated tokens:                  2457600   
Total generated tokens (retokenized):    2448836   
Request throughput (req/s):              0.27      
Input token throughput (tok/s):          276.74    
Output token throughput (tok/s):         276.74    
Total token throughput (tok/s):          553.48    
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6079389.87
Median E2E Latency (ms):                 7374173.14
---------------Time to First Token----------------
Mean TTFT (ms):                          2858184.95
Median TTFT (ms):                        1680440.41
P99 TTFT (ms):                           7511052.50
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          3148.78   
Median TPOT (ms):                        2974.87   
P99 TPOT (ms):                           6686.54   
---------------Inter-token Latency----------------
Mean ITL (ms):                           3148.57   
Median ITL (ms):                         2007.02   
P99 ITL (ms):                            2745.71   
==================================================
